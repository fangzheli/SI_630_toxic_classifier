{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21631a5c-155b-4add-a333-5036fd2a6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084ff632-6252-44e3-a2fc-bfdd8d5f2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_word(word):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Multilingual-MiniLM-L12-H384\")\n",
    "    return tokenizer.encode(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7245f17-8a55-4090-8a98-8613313222aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4127, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_word(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "902d0e02-fcd8-4c59-ad50-ca57f76cb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a431b50d-af38-4d9d-b1c2-42a32c6d1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "from pet.task_helpers import MultiMaskTaskHelper\n",
    "from pet.tasks import DataProcessor, PROCESSORS, TASK_HELPERS\n",
    "from pet.utils import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4062f14d-34d3-4f10-a684-264ac7d5579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTaskDataProcessor(DataProcessor):\n",
    "    \"\"\"\n",
    "    Example for a data processor.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set this to the name of the task\n",
    "    TASK_NAME = \"my-task\"\n",
    "\n",
    "    # Set this to the name of the file containing the train examples\n",
    "    TRAIN_FILE_NAME = \"hw4_train.csv\"\n",
    "\n",
    "    # Set this to the name of the file containing the dev examples\n",
    "    DEV_FILE_NAME = \"dev.csv\"\n",
    "\n",
    "    # Set this to the name of the file containing the test examples\n",
    "    TEST_FILE_NAME = \"hw4_test.csv\"\n",
    "\n",
    "    # Set this to the name of the file containing the unlabeled examples\n",
    "    UNLABELED_FILE_NAME = \"unlabeled.csv\"\n",
    "\n",
    "    # Set this to a list of all labels in the train + test data\n",
    "    # LABELS = [\"1\", \"2\", \"3\", \"4\"]\n",
    "    LABELS = [\"0\", \"1\"]\n",
    "\n",
    "    # Set this to the column of the train/test csv files containing the input's text a\n",
    "    TEXT_A_COLUMN = 1\n",
    "\n",
    "    # Set this to the column of the train/test csv files containing the input's text b or to -1 if there is no text b\n",
    "    TEXT_B_COLUMN = -1\n",
    "\n",
    "    # Set this to the column of the train/test csv files containing the input's gold label\n",
    "    LABEL_COLUMN = 2\n",
    "\n",
    "    def get_train_examples(self, data_dir: str) -> List[InputExample]:\n",
    "        \"\"\"\n",
    "        This method loads train examples from a file with name `TRAIN_FILE_NAME` in the given directory.\n",
    "        :param data_dir: the directory in which the training data can be found\n",
    "        :return: a list of train examples\n",
    "        \"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.TRAIN_FILE_NAME), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir: str) -> List[InputExample]:\n",
    "        \"\"\"\n",
    "        This method loads dev examples from a file with name `DEV_FILE_NAME` in the given directory.\n",
    "        :param data_dir: the directory in which the dev data can be found\n",
    "        :return: a list of dev examples\n",
    "        \"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.DEV_FILE_NAME), \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir) -> List[InputExample]:\n",
    "        \"\"\"\n",
    "        This method loads test examples from a file with name `TEST_FILE_NAME` in the given directory.\n",
    "        :param data_dir: the directory in which the test data can be found\n",
    "        :return: a list of test examples\n",
    "        \"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.TEST_FILE_NAME), \"test\")\n",
    "\n",
    "    def get_unlabeled_examples(self, data_dir) -> List[InputExample]:\n",
    "        \"\"\"\n",
    "        This method loads unlabeled examples from a file with name `UNLABELED_FILE_NAME` in the given directory.\n",
    "        :param data_dir: the directory in which the unlabeled data can be found\n",
    "        :return: a list of unlabeled examples\n",
    "        \"\"\"\n",
    "        return self._create_examples(os.path.join(data_dir, MyTaskDataProcessor.UNLABELED_FILE_NAME), \"unlabeled\")\n",
    "\n",
    "    def get_labels(self) -> List[str]:\n",
    "        \"\"\"This method returns all possible labels for the task.\"\"\"\n",
    "        return MyTaskDataProcessor.LABELS\n",
    "\n",
    "    def _create_examples(self, path, set_type, max_examples=-1, skip_first=0):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "\n",
    "        with open(path) as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            for idx, row in enumerate(reader):\n",
    "                guid = \"%s-%s\" % (set_type, idx)\n",
    "                label = row[MyTaskDataProcessor.LABEL_COLUMN]\n",
    "                text_a = row[MyTaskDataProcessor.TEXT_A_COLUMN]\n",
    "                text_b = row[MyTaskDataProcessor.TEXT_B_COLUMN] if MyTaskDataProcessor.TEXT_B_COLUMN >= 0 else None\n",
    "                example = InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label)\n",
    "                examples.append(example)\n",
    "\n",
    "        return examples\n",
    "\n",
    "\n",
    "# register the processor for this task with its name\n",
    "PROCESSORS[MyTaskDataProcessor.TASK_NAME] = MyTaskDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1cfb6e-8e6a-4cdc-a44b-a4b66e9dfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "To add a new task to PET, both a DataProcessor and a PVP for this task must\n",
    "be added. The PVP is responsible for applying patterns to inputs and mapping\n",
    "labels to their verbalizations (see the paper for more details on PVPs).\n",
    "This file shows an example of a PVP for a new task.\n",
    "\"\"\"\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from pet.pvp import PVP, PVPS\n",
    "from pet.utils import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "374ef2bc-1620-4fa0-9f47-88afece05f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTaskPVP(PVP):\n",
    "    \"\"\"\n",
    "    Example for a pattern-verbalizer pair (PVP).\n",
    "    \"\"\"\n",
    "\n",
    "    # Set this to the name of the task\n",
    "    TASK_NAME = \"my-task\"\n",
    "\n",
    "    # Set this to the verbalizer for the given task: a mapping from the task's labels (which can be obtained using\n",
    "    # the corresponding DataProcessor's get_labels method) to tokens from the language model's vocabulary\n",
    "    VERBALIZER = {\n",
    "        \"0\": [\"regular\", \"non-toxic\"],\n",
    "        \"1\": [\"toxic\", \"bad\", \"harmful\"]\n",
    "    }\n",
    "\n",
    "    def get_parts(self, example: InputExample):\n",
    "        \"\"\"\n",
    "        This function defines the actual patterns: It takes as input an example and outputs the result of applying a\n",
    "        pattern to it. To allow for multiple patterns, a pattern_id can be passed to the PVP's constructor. This\n",
    "        method must implement the application of all patterns.\n",
    "        \"\"\"\n",
    "\n",
    "        # We tell the tokenizer that both text_a and text_b can be truncated if the resulting sequence is longer than\n",
    "        # our language model's max sequence length.\n",
    "        text_a = self.shortenable(example.text_a)\n",
    "        # text_b = self.shortenable(example.text_b)\n",
    "\n",
    "        # For each pattern_id, we define the corresponding pattern and return a pair of text a and text b (where text b\n",
    "        # can also be empty).\n",
    "        if self.pattern_id == 0:\n",
    "            return [self.mask, ':', example.text_a], []\n",
    "        elif self.pattern_id == 1:\n",
    "            return [example.text_a,'. Overall, it was ', self.mask], []\n",
    "        elif self.pattern_id == 2:\n",
    "            return [example.text_a, '. That is really ', self.mask], []\n",
    "        elif self.pattern_id == 3:\n",
    "            return [example.text_a, '. What do you think of this comment ', self.mask], []\n",
    "        elif self.pattern_id == 4:\n",
    "            return [self.mask, '-', example.text_a], []\n",
    "        elif self.pattern_id == 5:\n",
    "            return [example.text_a, ' ', self.mask], []\n",
    "        elif self.pattern_id == 6:\n",
    "            return [example.text_a, '. In summary, it was ', self.mask], []\n",
    "        elif self.pattern_id == 7:\n",
    "            return [example.text_a, '. The comment was ', self.mask], []\n",
    "        elif self.pattern_id == 8:\n",
    "            return [example.text_a, '. All in all, the comment was ', self.mask], []\n",
    "        elif self.pattern_id == 9:\n",
    "            return [example.text_a, ', which is ', self.mask], []\n",
    "        else:\n",
    "            raise ValueError(\"No pattern implemented for id {}\".format(self.pattern_id))\n",
    "\n",
    "    def verbalize(self, label) -> List[str]:\n",
    "        return MyTaskPVP.VERBALIZER[label]\n",
    "\n",
    "\n",
    "# register the PVP for this task with its name\n",
    "PVPS[MyTaskPVP.TASK_NAME] = MyTaskPVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcf0965-c191-4978-8a79-45177ff7bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 cli.py \\\n",
    "--method pet \\\n",
    "--pattern_ids 0 1 2 3 4 5 6 7 8 9 \\\n",
    "--data_dir ./ \\\n",
    "--model_type 'bert' \\\n",
    "--model_name_or_path \"microsoft/MiniLM-L12-H384-uncased\" \\\n",
    "--task_name \"my-task\" \\\n",
    "--output_dir ./ \\\n",
    "--do_train\n",
    "# --do_eval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
